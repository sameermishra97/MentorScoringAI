üìò Mentor Scoring AI ‚Äì Technical Summary (Round 2 Submission)
Team: NeuroLearn
Institution: IIT Madras
Member: Sameer Mishra
Challenge: UpSkill India Challenge ‚Äì Techfest IIT Bombay 2025
________________________________________
üß© 1. Problem Statement
Assessing teaching quality at scale is difficult, subjective, and time-intensive. Institutions need an automated and unbiased mechanism to evaluate mentors based on clarity, engagement, tone, and conceptual depth from recorded sessions or transcripts.
________________________________________
ü§ñ 2. Objective
To develop an AI-powered evaluation system that analyzes mentor explanations and provides:
‚Ä¢	Quantitative scores (clarity, tone, depth, engagement)
‚Ä¢	Personalized feedback and insights
‚Ä¢	Optional speech-to-text conversion for audio mentors
________________________________________
‚öôÔ∏è 3. Technical Architecture
The system follows this workflow:
Input (Text/Audio) ‚Üí Preprocessing ‚Üí AI Scoring Engine (TextStat + Empath + Transformers) ‚Üí Score Aggregation ‚Üí Visualization (Radar Chart) ‚Üí Gradio Interface Output
(Refer to architecture.png for the full system diagram.)
________________________________________
üß† 4. Implementation Highlights
‚Ä¢	Modular code structure (src/ with mentor_scoring_ai.py, helper_functions.py, app.py)
‚Ä¢	Integrated Hugging Face sentiment model for tone analysis
‚Ä¢	Empath lexicon for topic-depth evaluation
‚Ä¢	TextStat for readability / clarity
‚Ä¢	Optional speech-to-text via SpeechRecognition
‚Ä¢	Gradio front-end for live AI feedback
________________________________________
üìä 5. Results
The prototype successfully evaluates text and audio inputs, providing:
‚Ä¢	Real-time mentor scoring (0-100 scale)
‚Ä¢	Interactive radar chart visualization
‚Ä¢	Insightful qualitative feedback
(See sample_output.png for example output.)
________________________________________
üßæ 6. Challenges & Solutions
Challenge	Approach
Lack of labeled mentor data	Used unsupervised readability & emotion metrics
Audio accuracy issues	Added text fallback and smoothing
Model latency	Truncated long text to improve inference speed
________________________________________
üöÄ 7. Roadmap
‚Ä¢	Add emotion detection from voice (MFCC features)
‚Ä¢	Fine-tune models on mentor-specific datasets
‚Ä¢	Build an institutional dashboard
‚Ä¢	Deploy scalable FastAPI backend on Render
________________________________________
üèÅ 8. Conclusion
Mentor Scoring AI demonstrates how AI can enhance education by providing consistent, data-driven feedback to teachers and mentors.
This functional prototype covers ~80% of the complete system pipeline and lays the foundation for future large-scale deployment.
________________________________________
üì© References
‚Ä¢	Hugging Face Transformers
‚Ä¢	TextStat Documentation
‚Ä¢	Empath Lexicon
‚Ä¢	Gradio Framework
‚Ä¢	SpeechRecognition Python API
